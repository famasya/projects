{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fajri/miniconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pkg_resources\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from experiment_ensemble import cross_validation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('newData/video_train.csv')\n",
    "test=pd.read_csv('newData/video_test.csv')\n",
    "all_data = train.append(test)\n",
    "\n",
    "def load_stp():\n",
    "    stp_set = set()\n",
    "    data_file = open('stop_word.dic')\n",
    "    for line in data_file:\n",
    "        line = line.strip()\n",
    "        if line not in stp_set:\n",
    "            stp_set.add(line)\n",
    "    data_file.close()\n",
    "    return stp_set\n",
    "\n",
    "def text_cleaner(text):\n",
    "    stopword = load_stp()\n",
    "    text = text.strip()\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    #text = re.sub('\\d', ' ', text)\n",
    "    text = re.sub(r'\\W+', ' ', text)\n",
    "    text = text.split(' ')\n",
    "    text = ' '.join(filter(lambda x: x.lower() not in stopword, text))\n",
    "    return text\n",
    "\n",
    "def text_cleaner_with_stemming(text):\n",
    "    stopword = load_stp()\n",
    "    text = text.strip()\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('\\r', ' ', text)\n",
    "    text = text.split(' ')\n",
    "    text = ' '.join(filter(lambda x: x.lower() not in stopword, text))\n",
    "    \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    output   = stemmer.stem(text)\n",
    "    stopword = load_stp()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_part(data):\n",
    "    clean_text = []\n",
    "    bitrate = []\n",
    "    label = []\n",
    "    for index, row in data.iterrows():\n",
    "        clean_text.append(text_cleaner(str(row['title'])) + ' ' +text_cleaner(str(row['description'])))\n",
    "        bitrate.append([row['original_bitrate'], row['original_audio_bitrate'], row['original_video_bitrate'], row['duration']])\n",
    "        label.append(row['is_spam'])\n",
    "        #print index\n",
    "    return clean_text, bitrate, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7977, 10)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_data.shape\n",
    "#def cross_validation(clean_text, label, clf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_text, bitrate, label = extract_part (all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "columns = ['is_spam', 'text', 'original_bitrate', 'original_audio_bitrate', 'original_video_bitrate', 'duration']\n",
    "df = pd.DataFrame(columns=columns)\n",
    "for i in range(len(clean_text)):\n",
    "    new_list = [label[i], clean_text[i]] + bitrate[i]\n",
    "    new_row = pd.DataFrame([new_list], columns=columns)\n",
    "    df = df.append(new_row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('all_video_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSVALIDATION ITERATION 1\n",
      "CROSSVALIDATION ITERATION 2\n",
      "CROSSVALIDATION ITERATION 3\n",
      "CROSSVALIDATION ITERATION 4\n",
      "CROSSVALIDATION ITERATION 5\n",
      "CROSSVALIDATION ITERATION 6\n",
      "CROSSVALIDATION ITERATION 7\n",
      "CROSSVALIDATION ITERATION 8\n",
      "CROSSVALIDATION ITERATION 9\n",
      "CROSSVALIDATION ITERATION 10\n",
      "(0.94833175273647363, 0.9657152693159482, 0.97563636471821202, 0.95750324408781551)\n"
     ]
    }
   ],
   "source": [
    "#Experiment TF\n",
    "data = pd.read_csv('all_video_clean_text.csv')\n",
    "clean_text = data['text']\n",
    "label = data['is_spam']\n",
    "from experiment_ensemble import cross_validation\n",
    "#text_clf = Pipeline([\n",
    "#    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "#    ('classifier', LogisticRegression())\n",
    "#])\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(30,3), batch_size=10,random_state=1, early_stopping=False, verbose=False, validation_fraction=0.15)\n",
    "text_clf = Pipeline([\n",
    "        ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        #('scaler', StandardScaler()),\n",
    "        ('clf', clf)\n",
    "])\n",
    "\n",
    "print (cross_validation(clean_text, label, text_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSVALIDATION ITERATION 1\n",
      "CROSSVALIDATION ITERATION 2\n",
      "CROSSVALIDATION ITERATION 3\n",
      "CROSSVALIDATION ITERATION 4\n",
      "CROSSVALIDATION ITERATION 5\n",
      "CROSSVALIDATION ITERATION 6\n",
      "CROSSVALIDATION ITERATION 7\n",
      "CROSSVALIDATION ITERATION 8\n",
      "CROSSVALIDATION ITERATION 9\n",
      "CROSSVALIDATION ITERATION 10\n",
      "(0.77008937309912828, 0.87011349803690496, 0.77008937309912828, 1.0)\n"
     ]
    }
   ],
   "source": [
    "#Experiment TFIDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(ngram_range=(1, 2))\n",
    "text_clf = Pipeline([\n",
    "        ('count_vectorizer', cv),\n",
    "        ('clf', svm.SVC(tol = 1))\n",
    "])\n",
    "\n",
    "#clf = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(30,3), batch_size=10,random_state=1, early_stopping=False, verbose=False, validation_fraction=0.15)\n",
    "#text_clf = Pipeline([\n",
    "#        ('count_vectorizer', cv),\n",
    "#        ('clf', clf)])\n",
    "\n",
    "print (cross_validation(clean_text, label, text_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSVALIDATION ITERATION 1\n",
      "CROSSVALIDATION ITERATION 2\n",
      "CROSSVALIDATION ITERATION 3\n",
      "CROSSVALIDATION ITERATION 4\n",
      "CROSSVALIDATION ITERATION 5\n",
      "CROSSVALIDATION ITERATION 6\n",
      "CROSSVALIDATION ITERATION 7\n",
      "CROSSVALIDATION ITERATION 8\n",
      "CROSSVALIDATION ITERATION 9\n",
      "CROSSVALIDATION ITERATION 10\n",
      "(0.97191659903461125, 0.98218604029849155, 0.97151589023349738, 0.9934864013135245)\n"
     ]
    }
   ],
   "source": [
    "# TF with bitrate\n",
    "\n",
    "data = pd.read_csv('all_video_clean_text.csv')\n",
    "clean_text = data['text']\n",
    "bitrate = data[['original_bitrate', 'original_audio_bitrate', 'original_video_bitrate', 'duration']]\n",
    "label = data['is_spam']\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier', clf)\n",
    "])\n",
    "clf_bitrate = svm.SVC(tol=1)\n",
    "\n",
    "print (cross_validation_with_bitrate(clean_text, bitrate.as_matrix(), label, text_clf, clf_bitrate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation_with_bitrate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-27cb8af2982b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mclf_bitrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcross_validation_with_bitrate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbitrate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclf_bitrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cross_validation_with_bitrate' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Experiment TFIDF with bitrate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv = TfidfVectorizer(ngram_range=(1, 2))\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(30,3), batch_size=10,random_state=1, early_stopping=False, verbose=False, validation_fraction=0.15)\n",
    "pipeline = Pipeline([\n",
    "        ('count_vectorizer', cv),\n",
    "        ('clf', clf)\n",
    "])\n",
    "clf_bitrate = svm.SVC(tol=1)\n",
    "print (cross_validation_with_bitrate(clean_text, bitrate.as_matrix(), label, pipeline, clf_bitrate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSVALIDATION ITERATION 1\n",
      "CROSSVALIDATION ITERATION 2\n",
      "CROSSVALIDATION ITERATION 3\n",
      "CROSSVALIDATION ITERATION 4\n",
      "CROSSVALIDATION ITERATION 5\n",
      "CROSSVALIDATION ITERATION 6\n",
      "CROSSVALIDATION ITERATION 7\n",
      "CROSSVALIDATION ITERATION 8\n",
      "CROSSVALIDATION ITERATION 9\n",
      "CROSSVALIDATION ITERATION 10\n",
      "(0.80971605942414493, 0.88991728787228297, 0.80501606719936092, 0.99560260586319238)\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(solver='adam', alpha=1e-4, hidden_layer_sizes=(30,3), batch_size=10,random_state=1, early_stopping=False, verbose=False, validation_fraction=0.15)\n",
    "clf_bitrate =  LogisticRegression()\n",
    "print (cross_validation(bitrate.as_matrix(), label, clf_bitrate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSSVALIDATION ITERATION 1\n",
      "CROSSVALIDATION ITERATION 2\n",
      "CROSSVALIDATION ITERATION 3\n",
      "CROSSVALIDATION ITERATION 4\n",
      "CROSSVALIDATION ITERATION 5\n",
      "CROSSVALIDATION ITERATION 6\n",
      "CROSSVALIDATION ITERATION 7\n",
      "CROSSVALIDATION ITERATION 8\n",
      "CROSSVALIDATION ITERATION 9\n",
      "CROSSVALIDATION ITERATION 10\n",
      "(0.9710409771836559, 0.98177872048354242, 0.96810483581590534, 0.99641746775773954)\n"
     ]
    }
   ],
   "source": [
    "# Ensemble TF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "data = pd.read_csv('all_video_clean_text.csv')\n",
    "clean_text = data['text']\n",
    "label = data['is_spam']\n",
    "bitrate = data[['original_bitrate', 'original_audio_bitrate', 'original_video_bitrate', 'duration']]\n",
    "\n",
    "text_clf_1 = Pipeline([\n",
    "        ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('clf', LogisticRegression())\n",
    "])\n",
    "text_clf_2 = Pipeline([\n",
    "        ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('clf', MultinomialNB())\n",
    "])\n",
    "text_clf_3 = Pipeline([\n",
    "        ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('clf', svm.SVC(tol=1))\n",
    "])\n",
    "\n",
    "bitrate_clf = svm.SVC(tol=1)\n",
    "\n",
    "from experiment_ensemble import cross_validation_ensemble\n",
    "\n",
    "print(cross_validation_ensemble(clean_text, bitrate.as_matrix(), label, [text_clf_1, text_clf_2, text_clf_3] , bitrate_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('all_video_clean_text.csv')\n",
    "clean_text = data['text']\n",
    "bitrate = data[['original_bitrate', 'original_audio_bitrate', 'original_video_bitrate', 'duration']]\n",
    "label = data['is_spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6143.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fajri/miniconda2/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "bitrate['label'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bitrate.to_csv('bitrate.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
